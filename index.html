<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Amirhossein's Website</title>

  <!-- Google Fonts -->
  <link rel="preconnect" href="https://fonts.gstatic.com">
  <link href="https://fonts.googleapis.com/css2?family=Montserrat:wght@100&family=Ubuntu:wght@300&display=swap" rel="stylesheet">

  <!-- Font-awesome -->
  <script defer src="https://use.fontawesome.com/releases/v5.0.7/js/all.js"></script>

  <!-- bootstrap css -->
  <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-EVSTQN3/azprG1Anm3QDgpJLIm9Nao0Yz1ztcQTwFspd3yD65VohhpuuCOmLASjC" crossorigin="anonymous">

  <link rel="stylesheet" href="css/styles.css">

  <!-- bootstrap javascript -->
  <script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.9.2/dist/umd/popper.min.js" integrity="sha384-IQsoLXl5PILFhosVNubq5LC7Qb9DXgDA9i+tQ8Zj3iwWAwPtgFTxbJ8NT4GN1R8p" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/js/bootstrap.min.js" integrity="sha384-cVKIPhGWiC2Al4u+LWgxfKTRIcfu0JTxR+EQDz/bgldoEyl4H0zUF0QKbrJ0EcQF" crossorigin="anonymous"></script>

</head>

<body>

  <section id="title">

    <div class="container-fluid">

      <!-- Nav Bar -->
      <nav class="navbar fixed-top navbar-expand-lg navbar-dark bg-dark">
        <a class="navbar-brand" href="">Amirhossein Kardoost</a>

        <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarTogglerDemo02" aria-controls="navbarTogglerDemo02" aria-expanded="false" aria-label="Toggle navigation">
          <span class="navbar-toggler-icon"></span>
        </button>

        <div class="collapse navbar-collapse" id="navbarTogglerDemo02">
          <ul class="navbar-nav ms-auto">
            <li class="navbar-item">
              <a class="nav-link" href="#contact-info">Contact</a>
            </li>
            <li class="navbar-item">
              <a target="_blank" class="nav-link" href="https://www.linkedin.com/in/amirhossein-kardoost-72911257/">LinkedIn</a>
            </li>
            <li>
              <a target="_blank" class="nav-link" href="https://github.com/Amirhk-dev">GitHub</a>
            </li>
            <li class="navbar-item">
              <a class="nav-link" href="https://scholar.google.com/citations?user=55umfgIAAAAJ&hl=en">Google Scholar</a>
            </li>
            <li class="navbar-item">
              <a class="nav-link" href="#publications">Publications</a>
            </li>
          </ul>
        </div>
      </nav>

      <!-- Title -->

      <div class="row">
        <div class="col-lg-9">
          <h1>
            Hi! I am a software engineer at the <a target="_blank" class="link-dark" href="https://www.xfel.eu/">European X-ray Free Electron Laser (EuXFEL)</a>
            working on microscope data and studying them via <a class="link-dark" href="#mask-r-cnn">deep learning-based</a> approaches.
            My goal is to implement software for a better sample workflow on the microscopes incorporating advanced machine learning approaches for image recognition.
            Recently, I received my Ph.D. in computer science from the <a target="_blank" class="link-dark"
            href="https://www.vc.informatik.uni-siegen.de/en/kardoost-amirhossein">University of Siegen, Germany</a>, supervised by
            <a target="_blank" class="link-dark" href="https://www.vc.informatik.uni-siegen.de/en/keuper-margret">Prof. Dr.-Ing. Margret Keuper</a>.
            My focus was on segmenting object instances and motion patterns in videos. I obtained my master's
            degree in computer science from <a target="_blank" class="link-dark" href="https://saarland-informatics-campus.de/en/">Saarland University</a>.
            My research interests lie in the area of machine learning and computer vision.
            I am interested in exploring instance segmentation on video and images, such as electron microscopy images.
            I am particularly interested in <a target="_blank" class="link-dark" href="https://en.wikipedia.org/wiki/Self-supervised_learning">self-supervised</a> methods.
            I served as a reviewer for several top-tier conferences, such as CVPR, ICCV, and AAAI.
          </h1>
        </div>

        <div class="col-lg-3">
          <div class="card profiles">
            <img src="images/amir-1.jpg" alt="profile photo" class="img-first">
            <!--<img src="images/amir-2.jpg" class="img-top" alt="profile photo color">-->
          </div>
        </div>
      </div>
    </div>
  </section>

  <section id="publications">
    <h3 class="section-heading">Publications</h3><br>
    <h3 class="subsection-heading">Journal Article</h3>
    <div class="container-fluid papers">
      <div class="row">
        <div class="col-lg-5">
          <img src="images/paper_6.png" alt="paper-photo" class="img-thumbnail">
        </div>
        <div class="col-lg-7">
          <h1 class="paper-info">Higher-Order Multicuts for Geometric Model Fitting and Motion Segmentation</h1>
          <h1 class="paper-info">Evgeny Levinkov*, <strong>Amirhossein Kardoost*</strong>, Bjoern Andres, Margret Keuper</h1>
          <h1 class="paper-info">(* Contributed equally)</h1>
          <h1 class="paper-info">TPAMI 2022</h1>
          <p>
            <a target="_blank" href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9706260" class="btn btn-primary" role="button" aria-pressed="true">pdf</a>
            <button class="btn btn-primary" type="button" data-bs-toggle="collapse" data-bs-target="#collapseAbstract6" aria-expanded="false" aria-controls="collapseExample">
              abstract
            </button>
            <button class="btn btn-primary" type="button" data-bs-toggle="collapse" data-bs-target="#collapseBibtex6" aria-expanded="false" aria-controls="collapseExample">
              bibtex
            </button>
          </p>
          <div class="collapse" id="collapseAbstract6">
            <div class="card card-body paper-abstract">
              The minimum cost lifted multicut problem is a generalization of the multicut problem (also known as correlation clustering) and is a means to optimizing a decomposition of a graph w.r.t. both positive and negative edge costs. It has been shown to be useful in a large variety of applications in computer vision thanks to the fact that multicut-based formulations do not require the number of components given a priori; instead, it is deduced from the solution. However, the standard multicut cost function is limited to pairwise relationships between nodes, while several important applications either require or can benefit from a higher-order cost function, i.e. hyper-edges. In this paper, we propose a pseudo-boolean formulation for a multiple model fitting problem. It is based on a formulation of any-order minimum cost lifted multicuts, which allows to partition an undirected graph with pairwise connectivity such as to minimize costs defined over any set of hyper-edges. As the proposed formulation is NP-hard and the branch-and-bound algorithm (as well as obtaining lower bounds) is too slow in practice, we propose an efficient local search algorithm for inference into resulting problems. We demonstrate versatility and effectiveness of our approach in several applications: 1) We define a geometric multiple model fitting, more specifically, a line fitting problem on all triplets of points and group points, that belong to the same line, together. 2) We formulate homography and motion estimation as a geometric model fitting problem where the task is to find groups of points that can be explained by the same geometrical transformation. 3) In motion segmentation our model allows to go from modeling translational motion to Euclidean or affine transformations, which improves the segmentation quality in terms of F-measure.
            </div>
          </div>
          <div class="collapse" id="collapseBibtex6">
            <div class="card card-body">
              @article{kardoost_tpami_2022, <br>
                author = {Levinkov, Evgeny and Kardoost, Amirhossein and Andres, Bjoern and Keuper, Margret}, <br>
                journal = {Transactions on Pattern Analysis and Machine Intelligence (TPAMI)}, <br>
                title = {Higher-Order Multicuts for Geometric Model Fitting and Motion Segmentation}, <br>
                year = {2022}, <br>
                doi={10.1109/TPAMI.2022.3148795} <br>
              }
            </div>
          </div>
        </div>
      </div>
    </div>

    <h3 class="subsection-heading">Conference Articles</h3>
    <div class="container-fluid papers">
      <div class="row">
        <div class="col-lg-5">
          <img src="images/paper_5.png" alt="paper-photo" class="img-thumbnail">
        </div>
        <div class="col-lg-7">
          <h1 class="paper-info">Uncertainty in Minimum Cost Multicuts for Image and Motion Segmentation</h1>
          <h1 class="paper-info"><strong>Amirhossein Kardoost</strong>, Margret Keuper</h1>
          <h1 class="paper-info">UAI 2021</h1>
          <p>
            <a target="_blank" href="https://arxiv.org/pdf/2105.07469.pdf" class="btn btn-primary" role="button" aria-pressed="true">pdf</a>
            <button class="btn btn-primary" type="button" data-bs-toggle="collapse" data-bs-target="#collapseAbstract5" aria-expanded="false" aria-controls="collapseExample">
              abstract
            </button>
            <button class="btn btn-primary" type="button" data-bs-toggle="collapse" data-bs-target="#collapseBibtex5" aria-expanded="false" aria-controls="collapseExample">
              bibtex
            </button>
          </p>
          <div class="collapse" id="collapseAbstract5">
            <div class="card card-body paper-abstract">
              The minimum cost lifted multicut approach has proven practically good performance in a wide range of applications such as image decomposition, mesh segmentation, multiple object tracking, and motion segmentation. It addresses such problems in a graph-based model, where real-valued costs are assigned to the edges between entities such that the minimum cut decomposes the graph into an optimal number of segments. Driven by a probabilistic formulation of minimum cost multicuts, we provide a measure for the uncertainties of the decisions made during the optimization. We argue that access to such uncertainties is crucial for many practical applications and conduct an evaluation by means of sparsifications on three different, widely used datasets in the context of image decomposition (BSDS-500) and motion segmentation (DAVIS2016 and FBMS59) in terms of variation of information (VI) and Rand index (RI).
            </div>
          </div>
          <div class="collapse" id="collapseBibtex5">
            <div class="card card-body">
              @inproceedings{kardoost_uai_2021, <br>
              author = {Kardoost, Amirhossein and Keuper, Margret}, <br>
              title = {Uncertainty in Minimum Cost Multicuts for Image and Motion Segmentation}, <br>
              booktitle = {Uncertainty in Artificial Intelligence (UAI)}, <br>
              year = {2021} <br>
              }
            </div>
          </div>
        </div>
      </div>
    </div>

    <div class="container-fluid papers">
      <div class="row">
        <div class="col-lg-5">
          <img src="images/paper_3.png" alt="paper-photo" class="img-thumbnail">
        </div>
        <div class="col-lg-7">
          <h1 class="paper-info">Self-supervised Sparse to Dense Motion Segmentation</h1>
          <h1 class="paper-info"><strong>Amirhossein Kardoost</strong>, Kalun Ho, Peter Ochs, Margret Keuper</h1>
          <h1 class="paper-info">ACCV 2020</h1>
          <p>
            <a target="_blank" href="https://openaccess.thecvf.com/content/ACCV2020/papers/Kardoost_Self-supervised_Sparse_to_Dense_Motion_Segmentation_ACCV_2020_paper.pdf" class="btn btn-primary" role="button" aria-pressed="true">pdf</a>
            <button class="btn btn-primary" type="button" data-bs-toggle="collapse" data-bs-target="#collapseAbstract3" aria-expanded="false" aria-controls="collapseExample">
              abstract
            </button>
            <button class="btn btn-primary" type="button" data-bs-toggle="collapse" data-bs-target="#collapseBibtex3" aria-expanded="false" aria-controls="collapseExample">
              bibtex
            </button>
            <a target="_blank" href="https://www.youtube.com/watch?v=eqpxBkxJ5NQ" class="btn btn-primary" role="button" aria-pressed="true">video</a>
            <a target="_blank" href="https://github.com/Amirhk-dev/Self-supervised-Sparse-to-Dense-Motion-Segmentation" class="btn btn-primary" role="button" aria-pressed="true">code</a>
          </p>
          <div class="collapse" id="collapseAbstract3">
            <div class="card card-body paper-abstract">
              Observable motion in videos can give rise to the definition of objects moving with respect to the scene. The task of segmenting such moving objects is referred to as motion segmentation and is usually tackled either by aggregating motion information in long, sparse point trajectories, or by directly producing per frame dense segmentations relying on large amounts of training data. In this paper, we propose a self supervised method to learn the densification of sparse motion segmentations from single video frames. While previous approaches towards motion segmentation build upon pre-training on large surrogate datasets and use dense motion information as an essential cue for the pixelwise segmentation, our model does not require pre-training and operates at test time on single frames. It can be trained in a sequence specific way to produce high quality dense segmentations from sparse and noisy input. We evaluate our method on the well-known motion segmentation datasets FBMS59 and DAVIS2016.
            </div>
          </div>
          <div class="collapse" id="collapseBibtex3">
            <div class="card card-body">
              @inproceedings{kardoost_accv_2020_a, <br>
              author = {Kardoost, Amirhossein and Ho, Kalun and Ochs, Peter and Keuper, Margret}, <br>
              title = {Self-supervised Sparse to Dense Motion Segmentation}, <br>
              booktitle = {Proceedings of the Asian Conference on Computer Vision (ACCV)}, <br>
              month = {November}, <br>
              year = {2020} <br>
              }
            </div>
          </div>
        </div>
      </div>
    </div>

    <div class="container-fluid papers">
      <div class="row">
        <div class="col-lg-5">
          <img src="images/paper_4.png" alt="paper-photo" class="img-thumbnail">
        </div>
        <div class="col-lg-7">
          <h1 class="paper-info">A Two-Stage Minimum Cost Multicut Approach to Self-Supervised Multiple Person Tracking</h1>
          <h1 class="paper-info">Kalun Ho, <strong>Amirhossein Kardoost</strong>, Franz-Josef Pfreundt, Janis Keuper, Margret Keuper</h1>
          <h1 class="paper-info">ACCV 2020</h1>
          <p>
            <a target="_blank" href="https://openaccess.thecvf.com/content/ACCV2020/papers/Ho_A_Two-Stage_Minimum_Cost_Multicut_Approach_to_Self-Supervised_Multiple_Person_ACCV_2020_paper.pdf" class="btn btn-primary" role="button"
              aria-pressed="true">pdf</a>
            <button class="btn btn-primary" type="button" data-bs-toggle="collapse" data-bs-target="#collapseAbstract4" aria-expanded="false" aria-controls="collapseExample">
              abstract
            </button>
            <button class="btn btn-primary" type="button" data-bs-toggle="collapse" data-bs-target="#collapseBibtex4" aria-expanded="false" aria-controls="collapseExample">
              bibtex
            </button>
          </p>
          <div class="collapse" id="collapseAbstract4">
            <div class="card card-body paper-abstract">
              Multiple Object Tracking (MOT) is a long-standing task in computer vision. Current approaches based on the tracking by detection paradigm either require some sort of domain knowledge or supervision to associate data correctly into tracks. In this work, we present a self-supervised multiple object tracking approach based on visual features and minimum cost lifted multicuts. Our method is based on straight-forward spatio-temporal cues that can be extracted from neighboring frames in an image sequences without supervision. Clustering based on these cues enables us to learn the required appearance invariances for the tracking task at hand and train an AutoEncoder to generate suitable latent representations. Thus, the resulting latent representations can serve as robust appearance cues for tracking even over large temporal distances where no reliable spatio-temporal features can be extracted. We show that, despite being trained without using the provided annotations, our model provides competitive results on the challenging MOT Benchmark for pedestrian tracking.
            </div>
          </div>
          <div class="collapse" id="collapseBibtex4">
            <div class="card card-body">
              @inproceedings{kardoost_accv_2020_b, <br>
              author = {Ho, Kalun and Kardoost, Amirhossein and Pfreundt, Franz-Josef and Keuper, Janis and Keuper, Margret}, <br>
              title = {A Two-Stage Minimum Cost Multicut Approach to Self-Supervised Multiple Person Tracking}, <br>
              booktitle = {Proceedings of the Asian Conference on Computer Vision (ACCV)}, <br>
              month = {November}, <br>
              year = {2020} <br>
              }
            </div>
          </div>
        </div>
      </div>
    </div>

    <div class="container-fluid papers">
      <div class="row">
        <div class="col-lg-5">
          <img src="images/paper_2.png" alt="paper-photo" class="img-thumbnail">
        </div>
        <div class="col-lg-7">
          <h1 class="paper-info">Object Segmentation Tracking from Generic Video Cues</h1>
          <h1 class="paper-info"><strong>Amirhossein Kardoost</strong>, Sabine Müller, Joachim Weickert, Margret Keuper</h1>
          <h1 class="paper-info">ICPR 2020</h1>
          <p>
            <a target="_blank" href="https://arxiv.org/pdf/1910.02258.pdf" class="btn btn-primary" role="button" aria-pressed="true">pdf</a>
            <button class="btn btn-primary" type="button" data-bs-toggle="collapse" data-bs-target="#collapseAbstract2" aria-expanded="false" aria-controls="collapseExample">
              abstract
            </button>
            <button class="btn btn-primary" type="button" data-bs-toggle="collapse" data-bs-target="#collapseBibtex2" aria-expanded="false" aria-controls="collapseExample">
              bibtex
            </button>
            <a target="_blank" href="https://www.youtube.com/watch?v=Vw-hnI6p8uU" class="btn btn-primary" role="button" aria-pressed="true">video</a>
          </p>
          <div class="collapse" id="collapseAbstract2">
            <div class="card card-body paper-abstract">
              We propose a light-weight variational framework for online tracking of object segmentations in videos based on optical flow and image boundaries. While high-end computer vision methods on this task rely on sequence specific training of dedicated CNN architectures, we show the potential of a variational model, based on generic video information from motion and color. Such cues are usually required for tasks such as robot navigation or grasp estimation. We leverage them directly for video object segmentation and thus provide accurate segmentations at potentially very low extra cost. Our simple method can provide competitive results compared to the costly CNN-based methods with parameter tuning. Furthermore, we show that our approach can be combined with state-of-the-art CNN-based segmentations in order to improve over their respective results. We evaluate our method on the datasets DAVIS16,17 and SegTrack v2.
            </div>
          </div>
          <div class="collapse" id="collapseBibtex2">
            <div class="card card-body">
              @inproceedings{kardoost_icpr_2021, <br>
              author={Kardoost, Amirhossein and Müller, Sabine and Weickert, Joachim and Keuper, Margret}, <br>
              booktitle={2020 25th International Conference on Pattern Recognition (ICPR)}, <br>
              title={Object Segmentation Tracking from Generic Video Cues}, <br>
              year={2021}, <br>
              doi={10.1109/ICPR48806.2021.9413089} <br>
              }
            </div>
          </div>
        </div>
      </div>
    </div>

    <div class="container-fluid papers">
      <div class="row">
        <div class="col-lg-5">
          <img src="images/paper_1.png" alt="paper-photo" class="img-thumbnail">
        </div>
        <div class="col-lg-7">
          <h1 class="paper-info">Solving Minimum Cost Lifted Multicut Problems by Node Agglomeration</h1>
          <h1 class="paper-info"><strong>Amirhossein Kardoost</strong>, Margret Keuper</h1>
          <h1 class="paper-info">ACCV 2018</h1>
          <p>
            <a target="_blank" href="https://web.informatik.uni-mannheim.de/akardoos/pdf-file/Solving_MCLMP_by_Node_Agglomeration.pdf" class="btn btn-primary" role="button" aria-pressed="true">pdf</a>
            <button class="btn btn-primary" type="button" data-bs-toggle="collapse" data-bs-target="#collapseAbstract1" aria-expanded="false" aria-controls="collapseExample">
              abstract
            </button>
            <button class="btn btn-primary" type="button" data-bs-toggle="collapse" data-bs-target="#collapseBibtex1" aria-expanded="false" aria-controls="collapseExample">
              bibtex
            </button>
            <a target="_blank" href="https://github.com/Amirhk-dev/Solving-Minimum-Cost-Lifted-Multicut-Problems-by-Node-Agglomeration" class="btn btn-primary" role="button" aria-pressed="true">code</a>
          </p>
          <div class="collapse" id="collapseAbstract1">
            <div class="card card-body paper-abstract">
              Despite its complexity, the minimum cost lifted multicut problem has found a wide range of applications in recent years, such as image and mesh decomposition or multiple object tracking. Its solutions are decompositions of a graph into an optimal number of segments which are optimized w.r.t. a cost function defined on a superset of the edge set. While the currently available solvers for this problem provide high quality solutions in terms of the task to be solved, they can have long computation times for more difficult problem instances. Here, we propose two variants of a heuristic solver (primal feasible heuristic), which greedily generate solutions within a bounded amount of time. Evaluations on image and mesh segmentation benchmarks show the high quality of these solutions.
            </div>
          </div>
          <div class="collapse" id="collapseBibtex1">
            <div class="card card-body">
              @inproceedings{kardoost_accv_2018, <br>
              TITLE = {Solving Minimum Cost Lifted Multicut Problems by Node Agglomeration}, <br>
              AUTHOR = {Kardoost, Amirhossein and Keuper, Margret}, <br>
              YEAR = {2018}, <br>
              BOOKTITLE = {ACCV 2018, 14th Asian Conference on Computer Vision}, <br>
              }
            </div>
          </div>
        </div>
      </div>
    </div>

    <div class="container-fluid papers">
      <div class="row">
        <div class="col-lg-5">
          <img src="images/paper_7.png" alt="paper-photo" class="img-thumbnail">
        </div>
        <div class="col-lg-7">
          <h1 class="paper-info">Optimizing Edge Detection for Image Segmentation with Multicut Penalties</h1>
          <h1 class="paper-info">Steffen Jung, Sebastian Ziegler, <strong>Amirhossein Kardoost</strong>, Margret Keuper</h1>
          <h1 class="paper-info">GCPR 2022</h1>
          <p>
            <a target="_blank" href="https://arxiv.org/pdf/2112.05416.pdf" class="btn btn-primary" role="button" aria-pressed="true">pdf</a>
            <button class="btn btn-primary" type="button" data-bs-toggle="collapse" data-bs-target="#collapseAbstract0" aria-expanded="false" aria-controls="collapseExample">
              abstract
            </button>
            <button class="btn btn-primary" type="button" data-bs-toggle="collapse" data-bs-target="#collapseBibtex0" aria-expanded="false" aria-controls="collapseExample">
              bibtex
            </button>
          </p>
          <div class="collapse" id="collapseAbstract0">
            <div class="card card-body paper-abstract">
              The Minimum Cost Multicut Problem (MP) is a popular way for obtaining a graph decomposition by optimizing binary edge labels over edge costs. While the formulation of a MP from independently estimated costs per edge is highly flexible and intuitive, solving the MP is NP-hard and time-expensive. As a remedy, recent work proposed to predict edge probabilities with awareness to potential conflicts by incorporating cycle constraints in the prediction process. We argue that such formulation, while providing a first step towards end-to-end learnable edge weights, is suboptimal, since it is built upon a loose relaxation of the MP. We therefore propose an adaptive CRF that allows to progressively consider more violated constraints and, in consequence, to issue solutions with higher validity. Experiments on the BSDS500 benchmark for natural image segmentation as well as on electron microscopic recordings show that our approach yields more precise edge detection and image segmentation.
            </div>
          </div>
          <div class="collapse" id="collapseBibtex0">
            <div class="card card-body">
              @inproceedings{gcpr_2022, <br>
                TITLE = {Optimizing Edge Detection for Image Segmentation with Multicut Penalties}, <br>
                AUTHOR = {Jung, Steffen and Ziegler, Sebastian and Kardoost, Amirhossein and Keuper, Margret}, <br>
                YEAR = {2022}, <br>
                BOOKTITLE = {GCPR, German Conference on Pattern Recognition}, <br>
              }
            </div>
          </div>
        </div>
      </div>
    </div>

    <h3 class="subsection-heading" id="mask-r-cnn">Technical Report</h3>
    <div class="container-fluid papers">
      <div class="row">
        <div class="col-lg-5">
          <img src="images/paper_8.png" alt="paper-photo" class="img-thumbnail">
        </div>
        <div class="col-lg-7">
          <h1 class="paper-info">Convolutional Neural Network Approach for the Automated Identification of in Cellulo Crystals</h1>
          <h1 class="paper-info"><strong>Amirhossein Kardoost</strong>, Robert Schönherr, Carsten Deiter, Lars Redecke, Kristina Lorenzen, Joachim Schulz, Iñaki de Diego</h1>
          <h1 class="paper-info">bioRxiv 2023</h1>
          <p>
            <a target="_blank" href="https://www.biorxiv.org/content/10.1101/2023.03.28.533948v1.full.pdf" class="btn btn-primary" role="button" aria-pressed="true">pdf</a>
            <button class="btn btn-primary" type="button" data-bs-toggle="collapse" data-bs-target="#collapseAbstract7" aria-expanded="false" aria-controls="collapseExample">
              abstract
            </button>
            <button class="btn btn-primary" type="button" data-bs-toggle="collapse" data-bs-target="#collapseBibtex7" aria-expanded="false" aria-controls="collapseExample">
              bibtex
            </button>
          </p>
          <div class="collapse" id="collapseAbstract7">
            <div class="card card-body paper-abstract">
              In cellulo crystallization is a rarely occurring event in nature. Recent advances, making use of heterologous overexpression, can promote the intracellular formation of protein crystals, but new tools are required to detect and to characterize these targets in the complex cell environment. In the present work we make use of Mask R-CNN, a Convolutional Neural Network (CNN) based instance segmentation method, for the identification of either single or multi-shaped crystals growing in living insect cells, using conventional bright field images. The algorithm can be rapidly adapted to recognize different targets, with the aim to extract relevant information to support a semi-automated screening pipeline, with the purpose to aid in the development of the intracellular protein crystallization approach.
            </div>
          </div>
          <div class="collapse" id="collapseBibtex7">
            <div class="card card-body">
              @article{biorxiv_2023, <br>
                author = {Amirhossein Kardoost, Robert Schönherr, Carsten Deiter, Lars Redecke, Kristina Lorenzen, Joachim Schulz, Iñaki de Diego}, <br>
                journal = {bioRxiv}, <br>
                title = {Convolutional Neural Network Approach for the Automated Identification of in Cellulo Crystals}, <br>
                year = {2023}, <br>
                doi={https://doi.org/10.1101/2023.03.28.533948} <br>
              }
            </div>
          </div>
        </div>
      </div>
    </div>

  </section>

  <footer class="white-section" id="footer">
    <div class="container-fluid">
      <p id="contact-info">✉ amirhossein.kardoost AT xfel.eu</p>
      <a class="link-website" href="https://amirhk-dev.github.io/">amirhk-dev.github.io</a>
      <div id="copyright">
        <hr>
        <p class="copyright-text">Powered by Bootstrap.</p>
      </div>
    </div>
  </footer>

</body>

</html>
